{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mjhoover1/Robust_MAML/blob/main/Torchmeta_MAML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jjVEiL3Gzr__"
   },
   "source": [
    "First, install the library torchmeta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rqIO-iA4zrzo",
    "outputId": "e371dcad-bdde-41e1-c7ff-074aa43316c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchmeta\n",
      "  Downloading torchmeta-1.8.0-py3-none-any.whl (210 kB)\n",
      "Collecting ordered-set\n",
      "  Downloading ordered-set-4.0.2.tar.gz (10 kB)\n",
      "Requirement already satisfied: tqdm>=4.0.0 in c:\\users\\bob12\\anaconda3\\lib\\site-packages (from torchmeta) (4.62.2)\n",
      "Requirement already satisfied: torch<1.10.0,>=1.4.0 in c:\\users\\bob12\\anaconda3\\lib\\site-packages (from torchmeta) (1.8.1)\n",
      "Requirement already satisfied: Pillow>=7.0.0 in c:\\users\\bob12\\anaconda3\\lib\\site-packages (from torchmeta) (8.3.1)\n",
      "Requirement already satisfied: requests in c:\\users\\bob12\\anaconda3\\lib\\site-packages (from torchmeta) (2.26.0)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\bob12\\anaconda3\\lib\\site-packages (from torchmeta) (1.20.3)\n",
      "Requirement already satisfied: torchvision<0.11.0,>=0.5.0 in c:\\users\\bob12\\anaconda3\\lib\\site-packages (from torchmeta) (0.9.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\bob12\\anaconda3\\lib\\site-packages (from torchmeta) (2.10.0)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\bob12\\anaconda3\\lib\\site-packages (from torch<1.10.0,>=1.4.0->torchmeta) (3.10.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\bob12\\anaconda3\\lib\\site-packages (from tqdm>=4.0.0->torchmeta) (0.4.4)\n",
      "Requirement already satisfied: six in c:\\users\\bob12\\anaconda3\\lib\\site-packages (from h5py->torchmeta) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bob12\\anaconda3\\lib\\site-packages (from requests->torchmeta) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\bob12\\anaconda3\\lib\\site-packages (from requests->torchmeta) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\bob12\\anaconda3\\lib\\site-packages (from requests->torchmeta) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bob12\\anaconda3\\lib\\site-packages (from requests->torchmeta) (3.2)\n",
      "Building wheels for collected packages: ordered-set\n",
      "  Building wheel for ordered-set (setup.py): started\n",
      "  Building wheel for ordered-set (setup.py): finished with status 'done'\n",
      "  Created wheel for ordered-set: filename=ordered_set-4.0.2-py2.py3-none-any.whl size=8219 sha256=487b082e5a50d14948dcdbbfb37607fe75b106f468317863270a7b123ff54125\n",
      "  Stored in directory: c:\\users\\bob12\\appdata\\local\\pip\\cache\\wheels\\a1\\09\\42\\0b963b1d5423ddc87cb4ba9f475e09838d3813300b52a866ea\n",
      "Successfully built ordered-set\n",
      "Installing collected packages: ordered-set, torchmeta\n",
      "Successfully installed ordered-set-4.0.2 torchmeta-1.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmeta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T1FxOV1Wzi8W"
   },
   "source": [
    "MAML example using torchmeta: Here is the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cU0HzCzozfJy"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchmeta.modules import (MetaModule, MetaSequential, MetaConv2d, MetaBatchNorm2d, MetaLinear)\n",
    "\n",
    "def conv3x3(in_channels, out_channels):\n",
    "  return MetaSequential(\n",
    "      MetaConv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "      MetaBatchNorm2d(out_channels, momentum=1., track_running_stats=False),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(2)\n",
    "  )\n",
    "\n",
    "class ConvolutionalNeuralNetwork(MetaModule):\n",
    "  def __init__(self, in_channels, out_features, hidden_size=64):\n",
    "    super(ConvolutionalNeuralNetwork, self).__init__()\n",
    "    self.in_channels = in_channels\n",
    "    self.out_features = out_features\n",
    "    self.hidden_size = hidden_size\n",
    "\n",
    "    self.features = MetaSequential(\n",
    "        conv3x3(in_channels, hidden_size),\n",
    "        conv3x3(hidden_size, hidden_size),\n",
    "        conv3x3(hidden_size, hidden_size),\n",
    "        conv3x3(hidden_size, hidden_size)\n",
    "    )\n",
    "\n",
    "    self.classifier = MetaLinear(hidden_size, out_features)\n",
    "\n",
    "  def forward(self, inputs, params=None):\n",
    "    features = self.features(inputs, params=self.get_subdict(params, 'features'))\n",
    "    features = features.view((features.size(0), -1))\n",
    "    logits = self.classifier(features, params=self.get_subdict(params, 'classifier'))\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RCMAJuItz01I"
   },
   "source": [
    "Here are the utility functions for the MAML example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Hm19YeABzltk"
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def get_accuracy(logits, targets):\n",
    "    \"\"\"Compute the accuracy (after adaptation) of MAML on the test/query points\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    logits : `torch.FloatTensor` instance\n",
    "        Outputs/logits of the model on the query points. This tensor has shape\n",
    "        `(num_examples, num_classes)`.\n",
    "    targets : `torch.LongTensor` instance\n",
    "        A tensor containing the targets of the query points. This tensor has \n",
    "        shape `(num_examples,)`.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    accuracy : `torch.FloatTensor` instance\n",
    "        Mean accuracy on the query points\n",
    "    \"\"\"\n",
    "    _, predictions = torch.max(logits, dim=-1)\n",
    "    return torch.mean(predictions.eq(targets).float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_JG_TfRz24C"
   },
   "source": [
    "Here is the training for the MAML example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "la0oxzmPz5SC",
    "outputId": "6ebad082-77b7-4da2-f5b4-06afdb3e017c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "au6BGjdoz9AF"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "from torchmeta.datasets.helpers import omniglot\n",
    "from torchmeta.utils.data import BatchMetaDataLoader\n",
    "from torchmeta.utils.gradient_based import gradient_update_parameters\n",
    "\n",
    "logger = logging.getLogger('example 1')\n",
    "\n",
    "def train(folder, device, num_shots=5, num_ways=5, batch_size=16, num_batches=100, num_workers=1, hidden_size=64, step_size=.4, first_order=True, output_folder=None):\n",
    "  dataset = omniglot(folder, shots=num_shots, ways=num_ways, shuffle=True, test_shots=15, \n",
    "                     meta_train=True, download=True)\n",
    "  dataloader = BatchMetaDataLoader(dataset, batch_size=batch_size, shuffle=True, \n",
    "                                   num_workers=num_workers)\n",
    "  model = ConvolutionalNeuralNetwork(1, num_ways, hidden_size=hidden_size)\n",
    "  model.to(device=device)\n",
    "  model.train()\n",
    "  meta_optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "  # Training loop\n",
    "  with tqdm(dataloader, total=num_batches) as pbar:\n",
    "    for batch_idx, batch in enumerate(pbar):\n",
    "\n",
    "      model.zero_grad()\n",
    "\n",
    "      train_inputs, train_targets = batch['train']\n",
    "      train_inputs = train_inputs.to(device=device)\n",
    "      train_targets = train_targets.to(device=device)\n",
    "\n",
    "      test_inputs, test_targets = batch['test']\n",
    "      test_inputs = test_inputs.to(device=device)\n",
    "      test_targets = test_targets.to(device=device)\n",
    "      \n",
    "      outer_loss = torch.tensor(0., device=device)\n",
    "      accuracy = torch.tensor(0., device=device)\n",
    "      for task_idx, (train_input, train_target, test_input,\n",
    "                     test_target) in enumerate(zip(train_inputs, train_targets,\n",
    "                                                   test_inputs, test_targets)):\n",
    "                       train_logit = model(train_input)\n",
    "                       inner_loss = F.cross_entropy(train_logit, train_target)\n",
    "\n",
    "                       model.zero_grad()\n",
    "                       params = gradient_update_parameters(model,\n",
    "                                                           inner_loss,\n",
    "                                                           step_size=step_size,\n",
    "                                                           first_order=first_order)\n",
    "                       \n",
    "                       test_logit = model(test_input, params=params)\n",
    "                       outer_loss += F.cross_entropy(test_logit, test_target)\n",
    "\n",
    "                       with torch.no_grad():\n",
    "                         accuracy += get_accuracy(test_logit, test_target)\n",
    "      outer_loss.div_(batch_size)\n",
    "      accuracy.div_(batch_size)\n",
    "\n",
    "      outer_loss.backward()\n",
    "      meta_optimizer.step()\n",
    "\n",
    "      pbar.set_postfix(accuracy='{0:.4f}'.format(accuracy.item()))\n",
    "      if batch_idx >= num_batches: break\n",
    "\n",
    "  # Save model\n",
    "  if output_folder is not None:\n",
    "    filename = os.path.join(output_folder, 'maml_omniglot_{0}shot_{1}way.th'.format(\n",
    "        num_shots, num_ways))\n",
    "    with open(filename, 'wb') as f:\n",
    "      state_dict = model.state_dict()\n",
    "      torch.save(state_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X9fyxHJ5z-V6"
   },
   "outputs": [],
   "source": [
    "# train(folder, device, num_shots=5, num_ways=5, batch_size=16, num_batches=100, num_workers=1, hidden_size=64, step_size=.4, first_order=True, output_folder=None):\n",
    "train(\"data\", device)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMzsb5BIHrxQpGQs2I0xrL8",
   "include_colab_link": true,
   "name": "Torchmeta_MAML.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
