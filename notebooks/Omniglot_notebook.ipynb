{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mjhoover1/Robust_MAML/blob/main/Omniglot_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import Omniglot\n",
    "from PIL import Image\n",
    "\n",
    "ds = Omniglot('data/', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]\n",
    "converter = transforms.ToTensor()\n",
    "img = converter(ds[0][0])\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tlo6_1-32hQz"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from skimage import io\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "from collections import OrderedDict\n",
    "from more_itertools import chunked\n",
    "from torchvision.datasets import Omniglot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mcK3ZmpS2imr"
   },
   "outputs": [],
   "source": [
    "n_shot = 1\n",
    "n_class = 10\n",
    "n_local_update = 5\n",
    "batch_size = n_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ReOnXn672ku2"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103,
     "referenced_widgets": [
      "097a6ba1c70f436d89601ef726b787bc",
      "14589dd90e0b457a82cb069fc66208e0",
      "d461e6c7b69c4d1f9e38e41c085a176b",
      "c0cef75e102d4bccb9ae9c808a896155",
      "19a5cb75aab8422e83f3aa29af98f629",
      "3a5095073b0e46f88e1f606300cbd364",
      "71ff586944a44f1598f5ef05ff07c556",
      "41fa27b6239b42a78a661a3fe45a4c85",
      "6ed9bbaf5dec4389bca5b9ec25dfc331",
      "8b45ba9827ac436b81315ada6b9973b8",
      "3a51e0046109494dba07d1a18e4adf64"
     ]
    },
    "id": "hNQ_rEAs3eAM",
    "outputId": "206cb35c-05ae-4a84-b5ef-85476f200357"
   },
   "outputs": [],
   "source": [
    "ds = Omniglot('data/', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GySD92Uc2oCG"
   },
   "outputs": [],
   "source": [
    "class OmniglotNet(nn.Module):\n",
    "    def __init__(self, n_class):\n",
    "        super(OmniglotNet, self).__init__()\n",
    "        \n",
    "        self.h=105\n",
    "        self.conv1 = nn.Conv2d(1, self.h, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(self.h, self.h, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(self.h, self.h, kernel_size=3)\n",
    "        self.bn1 = nn.BatchNorm2d(self.h, momentum=1, affine=True)\n",
    "        self.bn2 = nn.BatchNorm2d(self.h, momentum=1, affine=True)\n",
    "        self.bn3 = nn.BatchNorm2d(self.h, momentum=1, affine=True)\n",
    "        self.fc = nn.Linear(self.h, n_class)\n",
    "        \n",
    "        # init is very very important!!!\n",
    "        # no init version -> HASH:ef56239\n",
    "        init.xavier_normal_(self.conv1.weight)\n",
    "        init.constant_(self.conv1.bias, 0)\n",
    "        init.xavier_normal_(self.conv2.weight)\n",
    "        init.constant_(self.conv2.bias, 0)\n",
    "        init.xavier_normal_(self.conv3.weight)\n",
    "        init.constant_(self.conv3.bias, 0)\n",
    "        \n",
    "        init.constant_(self.bn1.weight, 1)\n",
    "        init.constant_(self.bn1.bias, 0)\n",
    "        init.constant_(self.bn2.weight, 1)\n",
    "        init.constant_(self.bn2.bias, 0)\n",
    "        init.constant_(self.bn3.weight, 1)\n",
    "        init.constant_(self.bn3.bias, 0)\n",
    "        \n",
    "        init.normal_(self.fc.weight, 0, 0.01)\n",
    "        init.constant_(self.fc.bias, 1) # not 0 but 1.\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.max_pool2d(F.relu(self.bn1(self.conv1(x))), 2)\n",
    "        x = F.max_pool2d(F.relu(self.bn2(self.conv2(x))), 2)\n",
    "        x = F.max_pool2d(F.relu(self.bn3(self.conv3(x))), 2)\n",
    "        print(x.shape)\n",
    "        # x = x.view(x.shape[0]*x.shape[1],*x.shape[2:])\n",
    "        #x = x.view(x.size(0), self.h)\n",
    "        x = self.fc(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    # for MAML local optimization\n",
    "    def manual_forward(self, x, params):\n",
    "        \n",
    "        x = F.conv2d(x, params['conv1.weight'].to(device), params['conv1.bias'].to(device))\n",
    "        dumy = torch.ones(np.prod(np.array(x.data.size()[1]))).cuda()*999999999999999999 # momentnum=1\n",
    "        x = F.batch_norm(x, dumy, dumy, params['bn1.weight'], params['bn1.bias'], True, momentum=1)\n",
    "        x = F.max_pool2d(F.relu(x), 2)\n",
    "        \n",
    "        x = F.conv2d(x, params['conv2.weight'].to(device), params['conv2.bias'].to(device))\n",
    "        dumy = torch.ones(np.prod(np.array(x.data.size()[1]))).cuda()*999999999999999999 # momentnum=1\n",
    "        x = F.batch_norm(x, dumy, dumy, params['bn2.weight'], params['bn2.bias'], True, momentum=1)\n",
    "        x = F.max_pool2d(F.relu(x), 2)\n",
    "        \n",
    "        x = F.conv2d(x, params['conv3.weight'].to(device), params['conv3.bias'].to(device))\n",
    "        dumy = torch.ones(np.prod(np.array(x.data.size()[1]))).cuda()*999999999999999999 # momentnum=1\n",
    "        x = F.batch_norm(x, dumy, dumy, params['bn3.weight'], params['bn3.bias'], True, momentum=1)\n",
    "        x = F.max_pool2d(F.relu(x), 2)\n",
    "        \n",
    "        x = x.view(x.size(0), self.h, -1)\n",
    "        x = F.linear(x, params['fc.weight'].to(device), params['fc.bias'].to(device))\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FaYbX1QmMQ83"
   },
   "outputs": [],
   "source": [
    "# class OmniglotNet(nn.Module):\n",
    "#     '''\n",
    "#     The base model for few-shot learning on Omniglot\n",
    "#     '''\n",
    "\n",
    "#     def __init__(self, num_classes, loss_fn, num_in_channels=3):\n",
    "#         super(OmniglotNet, self).__init__()\n",
    "#         # Define the network\n",
    "#         self.features = nn.Sequential(OrderedDict([\n",
    "#                 ('conv1', nn.Conv2d(num_in_channels, 64, 3)),\n",
    "#                 ('bn1', nn.BatchNorm2d(64, momentum=1, affine=True)),\n",
    "#                 ('relu1', nn.ReLU(inplace=True)),\n",
    "#                 ('pool1', nn.MaxPool2d(2,2)),\n",
    "#                 ('conv2', nn.Conv2d(64,64,3)),\n",
    "#                 ('bn2', nn.BatchNorm2d(64, momentum=1, affine=True)),\n",
    "#                 ('relu2', nn.ReLU(inplace=True)),\n",
    "#                 ('pool2', nn.MaxPool2d(2,2)),\n",
    "#                 ('conv3', nn.Conv2d(64,64,3)),\n",
    "#                 ('bn3', nn.BatchNorm2d(64, momentum=1, affine=True)),\n",
    "#                 ('relu3', nn.ReLU(inplace=True)),\n",
    "#                 ('pool3', nn.MaxPool2d(2,2))\n",
    "#         ]))\n",
    "#         self.add_module('fc', nn.Linear(64, num_classes))\n",
    "        \n",
    "#         # Define loss function\n",
    "#         self.loss_fn = loss_fn\n",
    "\n",
    "#         # Initialize weights\n",
    "#         self._init_weights()\n",
    "\n",
    "#     def forward(self, x, weights=None):\n",
    "#         ''' Define what happens to data in the net '''\n",
    "#         if weights == None:\n",
    "#             x = self.features(x)\n",
    "#             x = x.view(x.size(0), 64)\n",
    "#             x = self.fc(x)\n",
    "#         else:\n",
    "#             x = conv2d(x, weights['features.conv1.weight'], weights['features.conv1.bias'])\n",
    "#             x = batchnorm(x, weight = weights['features.bn1.weight'], bias = weights['features.bn1.bias'], momentum=1)\n",
    "#             x = relu(x)\n",
    "#             x = maxpool(x, kernel_size=2, stride=2) \n",
    "#             x = conv2d(x, weights['features.conv2.weight'], weights['features.conv2.bias'])\n",
    "#             x = batchnorm(x, weight = weights['features.bn2.weight'], bias = weights['features.bn2.bias'], momentum=1)\n",
    "#             x = relu(x)\n",
    "#             x = maxpool(x, kernel_size=2, stride=2) \n",
    "#             x = conv2d(x, weights['features.conv3.weight'], weights['features.conv3.bias'])\n",
    "#             x = batchnorm(x, weight = weights['features.bn3.weight'], bias = weights['features.bn3.bias'], momentum=1)\n",
    "#             x = relu(x)\n",
    "#             x = maxpool(x, kernel_size=2, stride=2) \n",
    "#             x = x.view(x.size(0), 64)\n",
    "#             x = linear(x, weights['fc.weight'], weights['fc.bias'])\n",
    "#         return x\n",
    "\n",
    "#     def net_forward(self, x, weights=None):\n",
    "#         return self.forward(x, weights)\n",
    "    \n",
    "#     def _init_weights(self):\n",
    "#         ''' Set weights to Gaussian, biases to zero '''\n",
    "#         torch.manual_seed(1337)\n",
    "#         torch.cuda.manual_seed(1337)\n",
    "#         torch.cuda.manual_seed_all(1337)\n",
    "#         print('init weights')\n",
    "#         for m in self.modules():\n",
    "#             if isinstance(m, nn.Conv2d):\n",
    "#                 n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "#                 m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "#                 if m.bias is not None:\n",
    "#                     m.bias.data.zero_()\n",
    "#             elif isinstance(m, nn.BatchNorm2d):\n",
    "#                 m.weight.data.fill_(1)\n",
    "#                 m.bias.data.zero_()\n",
    "#             elif isinstance(m, nn.Linear):\n",
    "#                 n = m.weight.size(1)\n",
    "#                 m.weight.data.normal_(0, 0.01)\n",
    "#                 #m.bias.data.zero_() + 1\n",
    "#                 m.bias.data = torch.ones(m.bias.data.size())\n",
    "    \n",
    "#     def copy_weights(self, net):\n",
    "#         ''' Set this module's weights to be the same as those of 'net' '''\n",
    "#         # TODO: breaks if nets are not identical\n",
    "#         # TODO: won't copy buffers, e.g. for batch norm\n",
    "#         for m_from, m_to in zip(net.modules(), self.modules()):\n",
    "#             if isinstance(m_to, nn.Linear) or isinstance(m_to, nn.Conv2d) or isinstance(m_to, nn.BatchNorm2d):\n",
    "#                 m_to.weight.data = m_from.weight.data.clone()\n",
    "#                 if m_to.bias is not None:\n",
    "#                     m_to.bias.data = m_from.bias.data.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TyQRW7Te2t7W"
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_data_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    \n",
    "    for data, target in train_data_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        train_acc += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    train_loss /= len(train_data_loader.dataset)\n",
    "    train_acc /= len(train_data_loader.dataset)\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nC0Qb0Nd2vom"
   },
   "outputs": [],
   "source": [
    "def test(model, device, test_data_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            \n",
    "            test_loss += loss\n",
    "            test_acc += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_data_loader.dataset)\n",
    "    test_acc /= len(test_data_loader.dataset)\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oh1pmdfG2w56"
   },
   "outputs": [],
   "source": [
    "class OmniglotOriginDataset(Dataset):\n",
    "    def __init__(self, path_to_lang, n_class, train, train_index, transform):\n",
    "\n",
    "        self.data = []\n",
    "        self.path = path_to_lang\n",
    "        \n",
    "        labels = sorted(os.listdir(path_to_lang))[:n_class]\n",
    "        \n",
    "        for label_i, label in enumerate(labels):\n",
    "            path_to_label = os.path.join(path_to_lang, label)\n",
    "            chars = np.array(sorted(os.listdir(path_to_label)))\n",
    "            if train:\n",
    "                chars = chars[train_index]\n",
    "            else:\n",
    "                test_index = list(set(np.arange(20)) - set(train_index)) # omniglot has 20 images per character\n",
    "                chars = chars[test_index]\n",
    "            for char in chars:\n",
    "                path_to_char = os.path.join(path_to_label, char)\n",
    "                image = io.imread(path_to_char)\n",
    "                label_i = np.array(label_i)\n",
    "                self.data.append([image, label_i])\n",
    "            \n",
    "        self.transform = transform\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        return self.transform(self.data[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JKmdnUzr23zq"
   },
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample[0], sample[1]\n",
    "        image = image / 255\n",
    "        image = (image-0.92208)/0.25140\n",
    "        image = image.reshape([105,105, 1])\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        image = np.array(image, np.float32)\n",
    "\n",
    "        return [torch.from_numpy(image), torch.from_numpy(label)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TKeaN8-q26DG"
   },
   "outputs": [],
   "source": [
    "class OmniglotAugmentedDataset(Dataset):\n",
    "    def __init__(self, path_to_chars, train, train_indices, transform):\n",
    "\n",
    "        self.data = []\n",
    "        self.path = NotImplementedError\n",
    "        \n",
    "        for label_i, (path_to_label, train_index) in enumerate(zip(path_to_chars, train_indices)):\n",
    "            chars = np.array(sorted(os.listdir(path_to_label)))\n",
    "            if train:\n",
    "                chars = chars[train_index]\n",
    "            else:\n",
    "                test_index = list(set(np.arange(20)) - set(train_index)) # omniglot has 20 images per character\n",
    "                chars = chars[test_index]\n",
    "            for char in chars:\n",
    "                path_to_char = os.path.join(path_to_label, char)\n",
    "                image = io.imread(path_to_char)\n",
    "                label_i = np.array(label_i)\n",
    "                self.data.append([image, label_i])\n",
    "            \n",
    "        self.transform = transform\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        return self.transform(self.data[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "k8cy1XmD3ARt",
    "outputId": "af5431a1-ad00-445e-d839-cd823eb66322"
   },
   "outputs": [],
   "source": [
    "local_task_train_data_loader = DataLoader(\n",
    "    OmniglotOriginDataset(\"/content/data/omniglot-py/images_background/Latin/\", \n",
    "                    n_class=n_class,\n",
    "                    train=True,\n",
    "                    train_index=[0],\n",
    "                    transform=transforms.Compose([\n",
    "                        ToTensor(),\n",
    "                    ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(\"local_task_train_data\")\n",
    "print(local_task_train_data_loader.dataset.path)\n",
    "\n",
    "for data, target in local_task_train_data_loader: # only have one batch\n",
    "    plt.figure(figsize=(10,1))\n",
    "    for i, x in enumerate(data):\n",
    "        plt.subplot(1, batch_size, i+1); plt.imshow(x[0])\n",
    "    plt.show()\n",
    "    print(\"y_true:\", target)\n",
    "    \n",
    "print(\"\\nlocal_task_test_data\")\n",
    "local_task_test_data_loader = DataLoader(\n",
    "    OmniglotOriginDataset(\"/content/data/omniglot-py/images_background/Latin\", \n",
    "                    n_class=n_class,\n",
    "                    train=False,\n",
    "                    train_index=[0],\n",
    "                    transform=transforms.Compose([\n",
    "                        ToTensor(),\n",
    "                    ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for data, target in local_task_test_data_loader: # only have one batch\n",
    "    plt.figure(figsize=(10,1))\n",
    "    for i, x in enumerate(data):\n",
    "        plt.subplot(1, batch_size, i+1); plt.imshow(x[0])\n",
    "    plt.show()\n",
    "    print(\"y_true:\", target)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "U0_RoEgM3Jvg",
    "outputId": "27828c53-d54b-4c88-b19d-9260b002da87"
   },
   "outputs": [],
   "source": [
    "local_task_train_data_loader = DataLoader(\n",
    "    OmniglotOriginDataset(\"/content/data/omniglot-py/images_background/Latin/\", \n",
    "                    n_class=n_class,\n",
    "                    train=True,\n",
    "                    train_index=[0],\n",
    "                    transform=transforms.Compose([\n",
    "                        ToTensor()\n",
    "                    ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "local_task_test_data_loader = DataLoader(\n",
    "    OmniglotOriginDataset(\"/content/data/omniglot-py/images_background/Latin/\", \n",
    "                    n_class=n_class,\n",
    "                    train=False,\n",
    "                    train_index=[0],\n",
    "                    transform=transforms.Compose([\n",
    "                        ToTensor()\n",
    "                    ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = OmniglotNet(n_class=10).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "with tqdm(range(10)) as _tqdm:\n",
    "    for epoch in _tqdm:\n",
    "        train_loss, train_acc = train(model, device, local_task_train_data_loader, optimizer, epoch)\n",
    "        test_loss, test_acc = test(model, device, local_task_test_data_loader)\n",
    "        _tqdm.set_postfix(OrderedDict(\n",
    "            epoch=epoch+1, \n",
    "            train_loss=train_loss, train_acc=train_acc, \n",
    "            test_loss=test_loss, test_acc=test_acc))\n",
    "        \n",
    "\n",
    "data, target = local_task_train_data_loader.__iter__().next()\n",
    "\n",
    "images = np.array(data).reshape(10,28,28)\n",
    "plt.figure(figsize=(10,1))\n",
    "[[plt.subplot(1,10,i+1), plt.imshow(img)] for i, img in enumerate(images)]; plt.show()\n",
    "\n",
    "print(\"y_pred:\", torch.argmax(model(data.cuda()), 1).cpu())\n",
    "print(\"y_true:\", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IUywXQmN354C",
    "outputId": "27b7847e-1a0d-4c8b-9fa5-e9d66dc20c4b"
   },
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ol-eYnkM37ji",
    "outputId": "cd5902b1-7694-4cc5-dca3-e6cf07fbd88e"
   },
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DCFZbA4N384h",
    "outputId": "56d5ec4f-a7d6-4121-dc8f-4927c6327a84"
   },
   "outputs": [],
   "source": [
    "%cd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w8cTLznG4VLj",
    "outputId": "6e60b951-eec2-478a-bfbb-850f4244ca5c"
   },
   "outputs": [],
   "source": [
    "%cd omniglot-py/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PT7dICAE4Y0b",
    "outputId": "9b6f325c-5d26-4e12-f29b-ba9e12f4dadc"
   },
   "outputs": [],
   "source": [
    "%cd images_background/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJ6BxsPV4cCz",
    "outputId": "eaae7d8f-e405-4119-e4bb-c5bed12f5a8c"
   },
   "outputs": [],
   "source": [
    "%cd Latin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rm8MdnMV4i5n"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN+LkT5JTaWj+6eKcENGt8E",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Omniglot_notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "097a6ba1c70f436d89601ef726b787bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d461e6c7b69c4d1f9e38e41c085a176b",
       "IPY_MODEL_c0cef75e102d4bccb9ae9c808a896155",
       "IPY_MODEL_19a5cb75aab8422e83f3aa29af98f629"
      ],
      "layout": "IPY_MODEL_14589dd90e0b457a82cb069fc66208e0"
     }
    },
    "14589dd90e0b457a82cb069fc66208e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "19a5cb75aab8422e83f3aa29af98f629": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3a51e0046109494dba07d1a18e4adf64",
      "placeholder": "​",
      "style": "IPY_MODEL_8b45ba9827ac436b81315ada6b9973b8",
      "value": " 9464832/? [00:00&lt;00:00, 45063160.10it/s]"
     }
    },
    "3a5095073b0e46f88e1f606300cbd364": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3a51e0046109494dba07d1a18e4adf64": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41fa27b6239b42a78a661a3fe45a4c85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6ed9bbaf5dec4389bca5b9ec25dfc331": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "71ff586944a44f1598f5ef05ff07c556": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b45ba9827ac436b81315ada6b9973b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c0cef75e102d4bccb9ae9c808a896155": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6ed9bbaf5dec4389bca5b9ec25dfc331",
      "max": 9464212,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_41fa27b6239b42a78a661a3fe45a4c85",
      "value": 9464212
     }
    },
    "d461e6c7b69c4d1f9e38e41c085a176b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_71ff586944a44f1598f5ef05ff07c556",
      "placeholder": "​",
      "style": "IPY_MODEL_3a5095073b0e46f88e1f606300cbd364",
      "value": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
